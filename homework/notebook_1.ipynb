{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a3999b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load de data\n",
    "\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "def load_data(zip_path):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path,\"r\") as z:\n",
    "            csv_filename=z.namelist()[0]\n",
    "\n",
    "            with z.open(csv_filename) as f:\n",
    "                df=pd.read_csv(f)\n",
    "        print(f\"File {csv_filename} uploaded succesfully\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\" Error loagind the file {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1209a3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_default_of_credit_card_clients.csv uploaded succesfully\n",
      "File train_default_of_credit_card_clients.csv uploaded succesfully\n"
     ]
    }
   ],
   "source": [
    "test_data=load_data(\"../files/input/test_data.csv.zip\")\n",
    "train_data=load_data(\"../files/input/train_data.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e3d47d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 25)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape\n",
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eb19cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "def data_cleaning(dataset, name=\"dataset\"):\n",
    "    dataset.rename(columns={\"default payment next month\":\"default\"}, inplace=True)\n",
    "    dataset.drop(columns=\"ID\",inplace=True)\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset.loc[dataset[\"EDUCATION\"]>4,\"EDUCATION\"]=4\n",
    "    print(f\"Data {name} cleaned successfully\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9b1e05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data train_data cleaned successfully\n",
      "Data test_data cleaned successfully\n"
     ]
    }
   ],
   "source": [
    "train_data=data_cleaning(train_data,\"train_data\")\n",
    "test_data=data_cleaning(test_data,\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a418f1c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>84373</td>\n",
       "      <td>57779</td>\n",
       "      <td>14163</td>\n",
       "      <td>8295</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1690</td>\n",
       "      <td>1138</td>\n",
       "      <td>930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2828</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>45975</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>0</td>\n",
       "      <td>46257</td>\n",
       "      <td>2200</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>40748</td>\n",
       "      <td>39816</td>\n",
       "      <td>40607</td>\n",
       "      <td>3700</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>270000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>22448</td>\n",
       "      <td>15490</td>\n",
       "      <td>17343</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0     310000    1          3         1   32      0      0      0      0   \n",
       "1      10000    2          3         1   49     -1     -1     -2     -1   \n",
       "2      50000    1          2         1   28     -1     -1     -1      0   \n",
       "3      80000    2          3         1   52      2      2      3      3   \n",
       "4     270000    1          1         2   34      1      2      0      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      0  ...      84373      57779      14163      8295      6000      4000   \n",
       "1      2  ...       1690       1138        930         0         0      2828   \n",
       "2     -1  ...      45975       1300      43987         0     46257      2200   \n",
       "3      3  ...      40748      39816      40607      3700      1600      1600   \n",
       "4      2  ...      22448      15490      17343         0      4000      2000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default  \n",
       "0      3000      1000      2000        0  \n",
       "1         0       182         0        1  \n",
       "2      1300     43987      1386        0  \n",
       "3         0      1600      1600        1  \n",
       "4         0      2000      2000        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c662780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "def split_data(train_data,test_data):\n",
    "    X_train=train_data.drop(columns=\"default\")\n",
    "    X_test=test_data.drop(columns=\"default\")\n",
    "\n",
    "    y_train=train_data[\"default\"]\n",
    "    y_test=test_data[\"default\"]\n",
    "\n",
    "    print(\"Correctly split dataset\")\n",
    "\n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3b48f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly split dataset\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = split_data(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e1d2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def classification_pipeline(X_train, y_train):\n",
    "\n",
    "    categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE']\n",
    "    numeric_cols = [c for c in X_train.columns if c not in categorical_cols]\n",
    "\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "            ('scaler', StandardScaler(with_mean=True, with_std=True), numeric_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA()),  \n",
    "        ('feature_selection', SelectKBest(score_func=f_classif)),\n",
    "        ('classifier', SVC( random_state=42))\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "07242081",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=classification_pipeline(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7d5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #4\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import numpy as np\n",
    "\n",
    "def Hyperparameter_optimization(model, X_train, y_train):\n",
    "\n",
    "    param_grid = {\n",
    "    'pca__n_components':[20],\n",
    "    'feature_selection__k':[12], \n",
    "    'classifier__kernel': ['rbf'], \n",
    "    'classifier__gamma': [0.099],\n",
    "}\n",
    "\n",
    "\n",
    "    \n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=132)\n",
    "\n",
    "    # GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        scoring='balanced_accuracy',\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        refit=True\n",
    "    )\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "582e55ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "model=Hyperparameter_optimization(model,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "863a167d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'metrics', 'dataset': 'train', 'precision': 0.7016, 'balanced_accuracy': 0.6644, 'recall': 0.3751, 'f1_score': 0.4888}\n",
      "{'type': 'metrics', 'dataset': 'test', 'precision': 0.6743, 'balanced_accuracy': 0.6675, 'recall': 0.385, 'f1_score': 0.4902}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, balanced_accuracy_score, recall_score, f1_score\n",
    "\n",
    "#predicciones\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "#métricas para entrenamiento\n",
    "precision_train = precision_score(y_train, y_pred_train, zero_division=0)\n",
    "balanced_acc_train = balanced_accuracy_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train, zero_division=0)\n",
    "f1_train = f1_score(y_train, y_pred_train, zero_division=0)\n",
    "\n",
    "#métricas para prueba\n",
    "precision_test = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "balanced_acc_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "recall_test = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "\n",
    "#resultados\n",
    "print({'type': 'metrics', 'dataset': 'train',\n",
    "       'precision': round(precision_train, 4),\n",
    "       'balanced_accuracy': round(balanced_acc_train, 4),\n",
    "       'recall': round(recall_train, 4),\n",
    "       'f1_score': round(f1_train, 4)})\n",
    "\n",
    "print({'type': 'metrics', 'dataset': 'test',\n",
    "       'precision': round(precision_test, 4),\n",
    "       'balanced_accuracy': round(balanced_acc_test, 4),\n",
    "       'recall': round(recall_test, 4),\n",
    "       'f1_score': round(f1_test, 4)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d723bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5\n",
    "import gzip \n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_model(model,path=\"file path.gzip\"):\n",
    "    os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "    with gzip.open(path,\"wb\") as f:\n",
    "        pickle.dump(model,f)\n",
    "    print(\"Model saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2d1536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "save_model(model,\"../files/models/model.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e9e2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "import os\n",
    "import json\n",
    "\n",
    "def metrics_evaluation(model,X_train,y_train,X_test,y_test,data_set_name=\"train or test\"):\n",
    "        \n",
    "          if data_set_name == \"train\":\n",
    "               y_true = y_train\n",
    "               y_pred = model.predict(X_train)\n",
    "          elif data_set_name == \"test\":\n",
    "               y_true = y_test\n",
    "               y_pred = model.predict(X_test)\n",
    "          else:\n",
    "               raise ValueError(\"data_set_name must be 'train' o 'test'\")\n",
    "\n",
    "          #Metrics \n",
    "          precision = precision_score(y_true, y_pred)\n",
    "          balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "          recall = recall_score(y_true, y_pred)\n",
    "          f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "          return {\n",
    "          \"type\": \"metrics\",\n",
    "          'dataset': data_set_name,\n",
    "          'precision': float(precision),\n",
    "          'balanced_accuracy': float(balanced_accuracy),\n",
    "          'recall': float(recall),\n",
    "          'f1_score': float(f1)\n",
    "          }\n",
    "\n",
    "def load_metrics(path,metrics_train,metrics_test):\n",
    "      os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "      with open(path,'w',encoding='utf-8') as f:\n",
    "            json.dump(metrics_train,f)\n",
    "            f.write('\\n')\n",
    "            json.dump(metrics_test,f)\n",
    "            f.write('\\n')\n",
    "      print(\"Metrics Saved!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71619c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics Saved!!\n"
     ]
    }
   ],
   "source": [
    "metrics_train=metrics_evaluation(model,X_train,y_train,X_test,y_test,\"train\")\n",
    "metrics_test=metrics_evaluation(model,X_train,y_train,X_test,y_test,\"test\")\n",
    "\n",
    "load_metrics(\"../files/output/metrics.json\",metrics_train,metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a669b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"train or test\"):\n",
    "        \n",
    "        if data_set_name == \"train\":\n",
    "             y_true = y_train\n",
    "             y_pred = model.predict(X_train)\n",
    "        elif data_set_name == \"test\":\n",
    "             y_true = y_test\n",
    "             y_pred = model.predict(X_test)\n",
    "        else:\n",
    "            raise ValueError(\"data_set_name must be 'train' o 'test'\")\n",
    "        \n",
    "        #Confusion matriz \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "          # Desempaquetar valores (para binario)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        return {\n",
    "        \"type\": \"cm_matrix\",\n",
    "        \"dataset\": data_set_name,\n",
    "        \"true_0\": {\"predicted_0\": int(tn), \"predicted_1\": int(fp)},\n",
    "        \"true_1\": {\"predicted_0\": int(fn), \"predicted_1\": int(tp)}\n",
    "        }\n",
    "\n",
    "def load_cm(path,cm_train,cm_test):\n",
    "      os.makedirs(os.path.dirname(path),exist_ok=True)\n",
    "\n",
    "      with open(path, 'a', encoding='utf-8') as f:\n",
    "        json.dump(cm_train, f)\n",
    "        f.write(\"\\n\")\n",
    "        json.dump(cm_test, f)\n",
    "        f.write(\"\\n\")\n",
    "        print(\"Metrics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19cf9b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 6736 FP: 355 FN: 1174 TP: 735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TN:\", tn, \"FP:\", fp, \"FN:\", fn, \"TP:\", tp)\n",
    "#TN: 6758 FP: 333 FN: 1196 TP: 713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "047b5776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved!\n"
     ]
    }
   ],
   "source": [
    "cm_train=cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"train\")\n",
    "\n",
    "cm_test=cm_metrics(model,X_train,y_train,X_test,y_test,data_set_name=\"test\")\n",
    "\n",
    "load_cm(\"../files/output/metrics.json\",cm_train,cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c3ad14c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'cm_matrix', 'dataset': 'train', 'true_0': {'predicted_0': 15519, 'predicted_1': 754}, 'true_1': {'predicted_0': 2954, 'predicted_1': 1773}}\n"
     ]
    }
   ],
   "source": [
    "print(cm_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
